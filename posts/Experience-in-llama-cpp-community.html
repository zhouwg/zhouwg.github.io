<!DOCTYPE html>
<html lang="en"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
    <!-- so meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5">
<meta property="og:type" content="article">
<meta property="og:title" content="Experience in llama.cpp communtiy">
<meta property="og:url" content="https://www.kantvai.com/posts/Experience-in-llama-cpp-community.html">
<meta property="og:site_name" content="study and thoughts">
<meta property="og:locale" content="en_US">
    <!-- title -->
    <title>Experience in llama.cpp communtiy</title>

<link rel="stylesheet" href="style.css">

<meta name="generator" content="Hexo 7.1.1 + VIM"></head>

<body class="max-width mx-auto px3 ltr">
      <div id="header-post">
      </div>

    <div class="content index py4 ">
        <article class="post h-entry" itemscope="" itemtype="http://schema.org/BlogPosting">
  <header>
    <h1 class="posttitle p-name" itemprop="name headline">
        Experience in llama.cpp community
    </h1>



    <div class="meta">
      <span class="author p-author h-card" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
        <span class="p-name" itemprop="name"></span>
      </span>
      
    <div class="postdate">
      
        <time datetime="2025-04-26" class="dt-published" itemprop="datePublished">2025-04-26</time>
        
      
    </div>
   </div>
 </header>
  

  <div class="content e-content" itemprop="articleBody">
    <p><b><i><font color="blue">Time flies like an arrow, one year has elapsed since I fall in love in llama.cpp commutiny since 03/2024.</font></i></b>(I completedly left Github on 07/18/2024 and I'm back to Github on 01/29/2025 due to DeepSeek-R1)</p>
<hr align="center" width="100%" color="#987cb9" size="2">


<p>
I have to say that I experienced a lot in llama.cpp community in this year.

</p>

<ul>
    <li> my journey in llama.cpp communtiy </li>

    <li> role of maintainers </li>

    <li> role of companies/institutions </li>

    <li> role of Intel </li>

    <li> Chinese in llama.cpp community </li>

    <li> dev costs</li>

    <li> thoughts </li>
</ul>

<p>

<h2>my journey in llama.cpp community</h2>
My first touch with llama.cpp community was on March/05/2024, details can be found at following link in my forked llama.cpp project:

<p><a target="_blank" rel="noopener" href="https://github.com/zhouwg/ggml-hexagon/discussions/18">https://github.com/zhouwg/ggml-hexagon/discussions/18</a></p>

Currently I have a formal condidated PR in llama.cpp community:

<p><a target="_blank" rel="noopener" href="https://github.com/ggml-org/llama.cpp/pull/12326">https://github.com/ggml-org/llama.cpp/pull/1232</a></p>

I think this openning PR might-be never get approved in llama.cpp community due to complex factors.


<h2>role of maintainers</h2>

<p>
I have to say that the original author of ggml/llama.cpp is too kind. as I said in my previous post: I have never seen a genius programmer as talneted as him in my career.
</p>

<p>
I think another original author of ggml/llama.cpp is a highly-speed computer and have widely tech knowledge, of course, he is also a kind programmer.
</p>

<p>
In the all, they are both AI experts and modern C++ masters, they are both the legendary 10x/100x programmers.
</p>

<br>

<h2>role of companies/institutions</h2>
<p>
I can clearly see that there are some maintainers/developers from various SoC vendors, such as Intel, AMD, Huawei, Loongson(this is a very famous desktop SoC vendor in Mainland China), Qualcomm, MUSA(this is a very very very hot SoC startup company in Mainland China because it's commonly considered as China's NVIDIA), IBM, NVIDIA,  ......
</p>

<p>
At the same time, I also can clearly see that there are some tech experts/developers from some top IT companies or institutions, such as Redhat, Google, Microsoft(MSRA or other MS's branch on our planet) Alibaba, ZhiPu(a hot AI startup from China's No.1 university Tsinghua University), ARM, VMWare, Huggingface, Docker, ISCAS(China's No.1 state-owned system software research institute)......

</p>

<br>
<p>

There are complex situations in some big well-known top IT giants because there are limited dev resource in different dev team and there are some non-tech factors in some big well-known top IT giants. I clearly know that and I clearly know everyone has a line manager in a big well-known top IT giants and they also can't agree on everything. one more thing, Qualcomm might-be want to keep a good balance between commercial and open-source regardless of technical direction/technical approach. so I have no negative opinions with anyone from Qualcomm. once again, I'd like to express my sincere thanks to a senior staff tech expert from Qualcomm whom gave me a breakthrough reminder/help on 03/18/2025(or 03/19/2025).
<br>
</p>

<h2>role of Intel in llama.cpp communtiy</h2>

Intel gave me a free printed copy of
<p><a target="_blank" ref="noopener" href="https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html">x86-32 Software Developer's Manual</a></p>
on 2005 and I never forget that although Intel is currently facing a very difficult situation(I think we should don't forget who helped you dig the well when you drink the water regardless of he/she/it is stronger/weaker at the moment).


<p>
I can clearly see that Intel is very actively participating in dev activity in llama.cpp commutiy for Intel's SYCL backend. Now many salaried programmers from Intel-owned company(Codeplay Software Ltd) are also actively involved in the development of Intel SYCL backend.
</p>

<p>
I'd like to say that Intel is a very important/great and open-minded IT giant. now Intel is facing a very difficult situation and I sincerely hope Intel can great again in the future.
</p>

<h2>Chinese in llama.cpp communtiy</h2>

 I'm not surprised that there are many wonderful llama.cpp derived projects in China because China has a population of 1.4 billion and 0.26 billion of them have received an university education. apparently there are many STEM genius in China. of course, there are also many individual tech experts/developers from China in the llama.cpp community.

<h2>dev costs</h2>

<p>
self-paid Android phone equipped with Qualcomm Snapdragon 8Gen3, purchased in 2024 and price is about USD 650(this is a dedicated phone for personal dev activity in llama.cpp community and before that I already purchased 8-10 Huawei's phones. accordingly, now 8Gen3 is my daily phone)
</p>
<p>
self-paid Android phone equipped with Qualcomm Snapdragon 8Elite, purchased in 2025 and price is about USD 500(this is also a dedicated phone for personal dev actvity in llama.cpp community, the price is smaller than 8Gen3 because of China's national subsidies on CE products in 2025)
</p>
<p>
self-paid Linux workstation: price is about USD 2000
</p>
<p>
self-paid paid-proxy(which required to reliable access to Github because of some known facts in China --- I also have no negative opinions with this policy because I understand running a such big country is really not easy after I learnt history of Ming dynasty since 05/2023. at the same time, I <b>have to</b> say that this policy is a very&big STUPID policy for STEM professionals in China whom only care STEM itself</a>
</p>

<p>
fulltime to that PR: 03/05/2024 ------ 06/15/2024
<br>
first formal PR on 04/24/2024 in llama.cpp community:
<p><a target="_blank" rel="noopener" href="https://github.com/ggml-org/llama.cpp/pull/6869">https://github.com/ggml-org/llama.cpp/pull/6869</a></p>

<p>
fulltime to that PR: 01/29/2025 ------ 04/24/2025
<br>
third formal PR on 03/11/2025 in llama.cpp community:
</p>
<p><a target="_blank" rel="noopener" href="https://github.com/ggml-org/llama.cpp/pull/12326">https://github.com/ggml-org/llama.cpp/pull/12326</a></p>


<h2>thoughts</h2>

I wrote an non-tech Chinese article on 03/17/2025 to describe my thoughts in llama.cpp community:
<p><a target="_blank" rel="noopener" href="https://github.com/zhouwg/ggml-hexagon/discussions/20">https://github.com/zhouwg/ggml-hexagon/discussions/20</a></p>

Please LLM helps me to translate this non-tech Chinese article to native English.

</p>

<hr align="center" width="100%" color="#987cb9" size="2">

<p>In the all, I think I learnt too much from llama.cpp community, not limited in pure tech area. that's all good things for me.</p>

</div>

</article>



<footer id="footer">
  <div class="footer-center">
    <nav>
      <ul>
        <li><a href="https://www.kantvai.com/">Home</a></li>
        <li><a href="https://www.kantvai.com/posts.html">Posts</a></li>
        <li><a target="_blank" rel="noopener" href="https://github.com/kantv-ai/">Projects</a></li>
      </ul>
    </nav>
  </div>
</footer>

    </div>
    <!-- styles -->



  <link rel="stylesheet" as="style" href="all.min.css" crossorigin="anonymous" onload="this.onload=null;this.rel='stylesheet'">


    <!-- jquery -->

  <script src="jquery.min.js" crossorigin="anonymous"></script>




<!-- clipboard -->

  
    <script src="clipboard.min.js" crossorigin="anonymous"></script>
  
  <script type="text/javascript">
  $(function() {
    // copy-btn HTML
    var btn = "<span class=\"btn-copy tooltipped tooltipped-sw\" aria-label=\"Copy to clipboard!\">";
    btn += '<i class="fa-regular fa-clone"></i>';
    btn += '</span>';
    // mount it!
    $(".highlight table").before(btn);
    var clip = new ClipboardJS('.btn-copy', {
      text: function(trigger) {
        return Array.from(trigger.nextElementSibling.querySelectorAll('.code')).reduce((str,it)=>str+it.innerText+'\n','')
      }
    });
    clip.on('success', function(e) {
      e.trigger.setAttribute('aria-label', "Copied!");
      e.clearSelection();
    })
  })
  </script>


<script src="main.js"></script>




</body></html>
